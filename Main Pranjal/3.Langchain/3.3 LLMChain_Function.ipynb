{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain_mistralai"
      ],
      "metadata": {
        "id": "kzDXQWprpADp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('random').strip()\n",
        "os.environ[\"MISTRAL_API_KEY\"] = api_key\n",
        "from langchain_mistralai import ChatMistralAI\n",
        "llm = ChatMistralAI(model=\"mistral-large-latest\")\n",
        "from langchain.prompts import PromptTemplate\n",
        "prompt_template_name= PromptTemplate(\n",
        "    input_variables=['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest me a fancy name.\"\n",
        ")\n",
        "\n",
        "#Importing LLMChain function\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "# LLMChain from the langchain library to combine a language model (llm) with a\n",
        "# PromptTemplate (prompt_template_name). This allows you to easily run the\n",
        "# language model with the defined prompt structure.\n",
        "\n",
        "chain=LLMChain(llm=llm, prompt=prompt_template_name)\n",
        "chain.run(\"Mexican\")\n"
      ],
      "metadata": {
        "id": "5SJqti9kq0NK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kjVvDyBduDoD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}